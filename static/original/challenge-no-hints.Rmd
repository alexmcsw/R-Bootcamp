# 2022 Innovation Camp Coding Challenge

## Table of Contents
- Introduction
- Instructions
    1. Load the data
    2. Clean the data
    3. Create a plot
    4. Do some analysis
    5. Prepare a report
- Further Directions

## Introduction

Rmarkdown files consist of blocks or chunks of code written in R and text written in markdown. You can run the code chunk by chunk or by knitting the entire document at once.

In the following chunk we load packages we will need and set preferences for knitting the document. Anything behind a "#" symbol is "commented code" and will be ignored by the compiler.
```{r, include = FALSE}
# Load libraries
library(cansim) # read in CODR/NDM tables
library(dplyr) # allows for data manipulation
library(tidyr) # allows for shaping the data
library(plotly) # for creating plots
library(lubridate) # for manipulating date-time objects

knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

## Instructions

### 1. Load the data
Today we will be working with [Stocks of specified dairy products](https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=3210000101#tables). This data is stored in a CODR (Census something something??) table
```{r}
# Load our data 
df <- get_cansim("32-10-0001-01")

```

Let's get to know the data a bit better. Let's checkout the columns and the range of values.
```{r}
# print a summary of our data


```

What are some things you notice about the data?

### 2. Clean the data
In short, "cleaning data" means to prepare it for analysis. Removing empty values, converting values to the same format or otherwise manipulating your data to improve the quality and uniformity are all examples of cleaning your data.

How might we need to clean this data?

```{r}
# drop uninteresting columns


# there are two date type columns. Let's keep the more precise one.


```

Now let's drop some columns we aren't really interested in. Using the above as an example, drop "SCALAR_FACTOR", "SCALAR_ID", and "DECIMALS". Note that there are many different equivalent ways to drop columns.

```{r}
# your code here

```

Notice that we have units in our data!
```{r}
#print which values appear in the UOM column


```
This result makes sense since we have solid and liquid diary products in our dataset. This is something that we may want to keep in mind as we conduct our analysis. Are there any other columns you'd like to investigate?
```{r}
# your code here

```

### 3. Create a plot
We're now a bit more familiar with our data, but it can be difficult to parse from a table! Let's create a plot so we can get a better idea of what's going on. What are some things we might want to find out and what is the best way to visualize them?

Since we have date information, it makes sense to make a time series plot! To keep things simple, let's focus on creamery butter in Canada over time.

```{r}

#create a bar plot showing total stocks of creamery butter in Canada over time


```

Using the code above, make a new plot showing the stocks of another dairy product in another region over time. Be sure to update the title as appropriate. 

```{r}
# your code here

```

We might also be curious about the breakdown of type of dairy product stocks. Let's visualize this in a pie chart. To keep it simple, let's focus on Canada and the most recent data, so June 2022. Recall the units we observed in part 1. Some of these stocks are measured in Tonnes (1000 kg) and some in Kiloliters (1000 L).
```{r}
# create a pie chart showing the composition of total dairy stocks in Canada in June 2022


```

Make another pie chart for another time period.
```{r}
# your code here

```

Or take a look at the different plot types here:https://plotly.com/r/ and try to plot something else
```{r}
# your code here

```
### 4. Do some analysis
Let's compute the yearly averages of each commodity. Recall the average of a set of values is given by the sum of the values divided by the size of the set. That being said, R has many basic mathematical functions built right in.

```{r}
# compute the yearly mean values for each commodity and region

```
Let's visualize this! Note that in the above code, we stored the filter under the variable "data" so we can refer to it later on.

```{r}
#create a bar plot showing the above mean values for Canada and Cheddar cheese


```



### 5. Prepare a report

In a separate document in this repository write a short summary of what you have learned. You can use whatever format you wish such as .txt, .md or .docs. You may wish to include some plots and/or special formatting or markdown.


## Challenge yourself!
Here are some extra tasks you can try.
1. Find out what is the most numerous commodity in Canada (or another region) over the years.

```{r}
# your code here

```
2. Compute the cheese stock per capita over time:
Access population data here:https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=1710000501

```{r}
# your code here

```



## Further Directions

1. Optimization:
Data.table is a structure that is faster than the built-in data.frame structure. Can you rewrite the code to make use of this structure instead? In what other ways could we speed up or optimize this script?

2. Collaboration:
You could put your code on Gitlab and have your colleagues provide feedback or even contribute to your code. Gitlab also provides version control so you can track changes to your project.

3. Interactivity:
[RShiny](https://shiny.rstudio.com/) is a tool to create interactive dashboards.Can you turn your report into an RShiny Dashboard?

4. What other ways could we improve this project using existing tools/techniques or otherwise?



